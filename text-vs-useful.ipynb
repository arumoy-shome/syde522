{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy.sparse import csr_matrix, csc_matrix, hstack, vstack\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.preprocessing import normalize\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn import metrics\n",
    "\n",
    "SAMPLE_SIZE = 500"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "reviews = pd.read_csv('dataset/review.csv', usecols=['text', 'useful'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "useful_reviews shape:  (500, 2)\n",
      "not_useful_reviews shape:  (500, 2)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<bound method NDFrame.head of                                                       text  useful\n",
       "3611417  We weren't sure if we should try based on some...       0\n",
       "650464   Our stay here was excellent. I enjoyed the siz...       0\n",
       "2057244  This was a horrible experience! I booked a hot...       0\n",
       "1995564  Four stars for the food, 3.25 stars for the se...       0\n",
       "4989961  702Connections got us squared away with transp...       3\n",
       "4235029  We had a full physical inspection of our home ...       3\n",
       "3248745  I've ate here about 5 times now, it's about a ...       0\n",
       "3186365  Our server was not the best.  He did not provi...       0\n",
       "3351716  Had to write a review because the most recent ...       2\n",
       "2679511  I go to yard house quite a bit. It is my favor...       0\n",
       "3149570  NOM - tried the \"Snicker\" this trip...so good!...       0\n",
       "1353348  Delicious. Was intimidating walking in without...       0\n",
       "1562106  Love, love, love this stadium! But we had a bo...      10\n",
       "1070756  I had the tonkatsu ramen, stir fry (udon) with...       4\n",
       "992048   Gahhh I love this place so much! This is my go...       2\n",
       "1528995  This restraunt is all hype, im sure most of th...       3\n",
       "4476054  i have been a big fan of Mimi's cafe for years...       0\n",
       "4341364  Incredibly Disappointing On All Levels: We wen...       0\n",
       "1971105  The service is fast and the servers are very f...       0\n",
       "1101994  The Lakeview has become a staple since I moved...       0\n",
       "1270908  I stopped in Mattie's on a Sunday morning in s...       0\n",
       "3584805  Making a reservation here was a HUGE mistake. ...       5\n",
       "3466986  Pricey, but one of the best coffee shops aroun...       0\n",
       "3496871  The food was good. The service was pretty good...       0\n",
       "2704069  Over the years this place has gone down hill. ...       3\n",
       "4311229  I painted with a friend for a Wine and Canvas ...       4\n",
       "206290   Nice restaurant with good fast service. I love...       0\n",
       "4828187  This place is located in Sola Salon building.S...       2\n",
       "4889451  https://www.youtube.com/watch?v=-avpx8UTakI\\n\\...       8\n",
       "3033530  Pretty cool-looking bar. Of course, it's cowbo...       0\n",
       "...                                                    ...     ...\n",
       "299823   Very cool store!! They have a great selection ...       9\n",
       "4469945  We went to Ellis Island on our last visit to V...       0\n",
       "4601975  Wonderful! Clean salon, Kenny is great!  Alrea...       0\n",
       "2979707  Nowhere else can you get Nars blush and a Fren...       3\n",
       "2954741  Amazing food, great lemonade and the folks wor...       0\n",
       "4428235  Well that was a surprise for airport food! Gre...       0\n",
       "1176608  I've been coming here for years and they are t...       0\n",
       "1834073  This place is super cheap and super yummy.  I ...       2\n",
       "558295   So bad I had to actually write a review...\\n\\n...       6\n",
       "4867947  The food at Cafe Zinho is fun, creative, and a...       3\n",
       "230352   Two things I noticed during my sessions here:\\...       6\n",
       "3553532  I used to go this driving range all the time b...       0\n",
       "3645330  The very best shoes for people that walk, trav...       2\n",
       "304695   Not impressed at all. Average Sandwich ok soup...       0\n",
       "4935844  I have contacted Amazon to let them know how a...      13\n",
       "4344559  Love this place. Favorite things: free salsa b...       2\n",
       "1557043  My first foot reflexogie massage!  Didn't know...       2\n",
       "2173283  I just want to thank Cecel for a very good job...       0\n",
       "3354718  Super disappointed.  I read about the bakery a...       0\n",
       "3198194  I love a good Mexican restaurant, and I also l...       7\n",
       "1016003  The food selection at this airport isn't the b...       3\n",
       "1065716  Had a very poor experience here. Firstly I'm n...       2\n",
       "3808659  I am a huge fan of Al's Thursday drink special...       0\n",
       "2320707  Met a friend here after work one night and he ...       0\n",
       "965646   I've had a lot of pub food, and I would say Mu...       2\n",
       "2154057  I really like this car wash for its location, ...       0\n",
       "3104801  It has become one of my favorites when catchin...       0\n",
       "1498524  Actually went to Palace Station to go to the O...       0\n",
       "2307980  Had the strip steak medium rare with the Chica...       0\n",
       "3342888  Its a bit different from what most people thin...       2\n",
       "\n",
       "[1000 rows x 2 columns]>"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "THRESHOLD = round(reviews['useful'].mean()) \n",
    "\n",
    "useful_reviews = reviews.loc[reviews['useful'] >= THRESHOLD].sample(SAMPLE_SIZE)\n",
    "not_useful_reviews = reviews.loc[reviews['useful'] < THRESHOLD].sample(SAMPLE_SIZE)\n",
    "print(\"useful_reviews shape: \", useful_reviews.shape)\n",
    "print(\"not_useful_reviews shape: \", not_useful_reviews.shape)\n",
    "\n",
    "reviews = shuffle(pd.concat([useful_reviews, not_useful_reviews]))\n",
    "reviews.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocessing\n",
    "\n",
    "For `text` a custom `analyzer` method is written which:\n",
    "1. remove all punctuations and\n",
    "3. removes new line characters (escape sequence)\n",
    "\n",
    "The feature extraction (`CountVectorize` and `TfidfVectorizer`) class is then set to:\n",
    "2. remove accents\n",
    "2. remove all stopwords\n",
    "3. lowercase all words\n",
    "\n",
    "For `useful` votes:\n",
    "2. remove df row if `useful` is `NaN`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "reviews shape after dropping NaN values:  (1000, 2)\n"
     ]
    }
   ],
   "source": [
    "reviews.dropna(inplace=True)\n",
    "print(\"reviews shape after dropping NaN values: \", reviews.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "import string\n",
    "import re\n",
    "\n",
    "RE_NEWLINE = '\\n+'\n",
    "PUNCTUATIONS = string.punctuation\n",
    "\n",
    "def review_process(review):\n",
    "    no_newline = re.sub(RE_NEWLINE, '', review)\n",
    "    no_punc = ''.join([char for char in no_newline if char not in PUNCTUATIONS])\n",
    "    \n",
    "    return no_punc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a str with some 2 punctuations 6546721 and numbers   \n"
     ]
    }
   ],
   "source": [
    "test = \"a str.. with! some @2 punctuations 6546721 and numbers \\n [] \\n\"\n",
    "print(review_process(test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
       "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
       "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
       "        ngram_range=(1, 1), norm='l2',\n",
       "        preprocessor=<function review_process at 0x147a98400>,\n",
       "        smooth_idf=True, stop_words='english', strip_accents='ascii',\n",
       "        sublinear_tf=False, token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b',\n",
       "        tokenizer=None, use_idf=True, vocabulary=None)"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vect = TfidfVectorizer(strip_accents='ascii', preprocessor=review_process, stop_words='english' )\n",
    "vect"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generating labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "NOT_USEFUL = 0\n",
    "USEFUL = 1\n",
    "\n",
    "def labeler(vote):\n",
    "    if math.floor(vote) < THRESHOLD:\n",
    "        return NOT_USEFUL\n",
    "    else:\n",
    "        return USEFUL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>useful</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3611417</th>\n",
       "      <td>We weren't sure if we should try based on some...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>650464</th>\n",
       "      <td>Our stay here was excellent. I enjoyed the siz...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2057244</th>\n",
       "      <td>This was a horrible experience! I booked a hot...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1995564</th>\n",
       "      <td>Four stars for the food, 3.25 stars for the se...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4989961</th>\n",
       "      <td>702Connections got us squared away with transp...</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                      text  useful  label\n",
       "3611417  We weren't sure if we should try based on some...       0      0\n",
       "650464   Our stay here was excellent. I enjoyed the siz...       0      0\n",
       "2057244  This was a horrible experience! I booked a hot...       0      0\n",
       "1995564  Four stars for the food, 3.25 stars for the se...       0      0\n",
       "4989961  702Connections got us squared away with transp...       3      1"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reviews['label'] = reviews['useful'].apply(labeler)\n",
    "    \n",
    "reviews.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generating test train splits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, Y_train, Y_test = train_test_split(reviews[['text', 'useful']], reviews['label'], test_size=0.4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Instantiate classifiers\n",
    "\n",
    "We will be using 3 classifiers for this analysis namely, *Multinomial Naive Bayes*, *Linear SVM* and *Random Forest*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MultinomialNB(alpha=1.0, class_prior=None, fit_prior=True)\n",
      "\n",
      "\n",
      "LinearSVC(C=1.0, class_weight=None, dual=True, fit_intercept=True,\n",
      "     intercept_scaling=1, loss='squared_hinge', max_iter=1000,\n",
      "     multi_class='ovr', penalty='l2', random_state=None, tol=0.0001,\n",
      "     verbose=0)\n",
      "\n",
      "\n",
      "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
      "            max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
      "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "            min_samples_leaf=1, min_samples_split=2,\n",
      "            min_weight_fraction_leaf=0.0, n_estimators=10, n_jobs=1,\n",
      "            oob_score=False, random_state=None, verbose=0,\n",
      "            warm_start=False)\n"
     ]
    }
   ],
   "source": [
    "mn_clas = MultinomialNB()\n",
    "print(mn_clas)\n",
    "print(\"\\n\")\n",
    "svc_clas = LinearSVC()\n",
    "print(svc_clas)\n",
    "print(\"\\n\")\n",
    "\n",
    "rf_clas = RandomForestClassifier()\n",
    "print(rf_clas)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model 1: training with only text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<600x9206 sparse matrix of type '<class 'numpy.float64'>'\n",
       "\twith 32307 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X1 = vect.fit_transform(X_train['text'])\n",
    "X1_test = vect.transform(X_test['text'])\n",
    "X1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "scipy.sparse.csr.csr_matrix"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(X1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "            max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
       "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "            min_samples_leaf=1, min_samples_split=2,\n",
       "            min_weight_fraction_leaf=0.0, n_estimators=10, n_jobs=1,\n",
       "            oob_score=False, random_state=None, verbose=0,\n",
       "            warm_start=False)"
      ]
     },
     "execution_count": 127,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mn_clas.fit(X1, Y_train)\n",
    "svc_clas.fit(X1, Y_train)\n",
    "rf_clas.fit(X1, Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Naive Bayes score:  0.59\n",
      "Linear SVC score:  0.6375\n",
      "Random Forest score:  0.6525\n"
     ]
    }
   ],
   "source": [
    "print(\"Naive Bayes score: \", mn_clas.score(X1_test, Y_test))\n",
    "print(\"Linear SVC score: \", svc_clas.score(X1_test, Y_test))\n",
    "print(\"Random Forest score: \", rf_clas.score(X1_test, Y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model 2: training with text and useful votes\n",
    "\n",
    "Since X now contains mixed dtypes, we need to be a bit clever. First, we convert `useful` column for train and test into sparse matrix and *I2* normalize them (I2 is the default for `TfidfVectorizer` so that's what we use here as well).\n",
    "\n",
    "The rest is straight forward, we create our updated X by stacking the `useful` sparse matrices with X horizontally (such that the number of feature increases). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "type of useful_sparse_train:  <class 'scipy.sparse.csr.csr_matrix'>\n",
      "shape of useful_sparse_train:  (1, 600)\n"
     ]
    }
   ],
   "source": [
    "useful_sparse_train = normalize(csr_matrix(X_train['useful']))\n",
    "useful_sparse_test = normalize(csr_matrix(X_test['useful']))\n",
    "print(\"type of useful_sparse_train: \", type(useful_sparse_train))\n",
    "print(\"shape of useful_sparse_train: \", useful_sparse_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "# training\n",
    "X2 = hstack([X1, useful_sparse_train.T])\n",
    "\n",
    "# testing\n",
    "X2_test = hstack([X1_test, useful_sparse_test.T])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "            max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
       "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "            min_samples_leaf=1, min_samples_split=2,\n",
       "            min_weight_fraction_leaf=0.0, n_estimators=10, n_jobs=1,\n",
       "            oob_score=False, random_state=None, verbose=0,\n",
       "            warm_start=False)"
      ]
     },
     "execution_count": 129,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mn_clas.fit(X2, Y_train)\n",
    "svc_clas.fit(X2, Y_train)\n",
    "rf_clas.fit(X2, Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Naive Bayes score:  0.6275\n",
      "Linear SVC score:  0.755\n",
      "Random Forest score:  0.8325\n"
     ]
    }
   ],
   "source": [
    "print(\"Naive Bayes score: \", mn_clas.score(X2_test, Y_test))\n",
    "print(\"Linear SVC score: \", svc_clas.score(X2_test, Y_test))\n",
    "print(\"Random Forest score: \", rf_clas.score(X2_test, Y_test))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
