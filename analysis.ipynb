{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Are useful votes on a review biased?\n",
    "\n",
    "Do users actually read a review before voting it useful? Or is their decision biased based on the cool, funny and useful votes previously received by the review?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from sklearn import metrics\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.preprocessing import normalize\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.feature_selection import VarianceThreshold\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.svm import LinearSVC\n",
    "\n",
    "from scipy.sparse import csr_matrix, csc_matrix, hstack, vstack\n",
    "SAMPLE_SIZE = 500"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "reviews = pd.read_csv('dataset/review.csv', usecols=['text', 'useful', 'cool'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We need to make sure that we have equal number of data points for each label. We use the mean of `useful` column as our threshold, any review with a `useful` vote lesser than the mean is labeled *not useful* and anything equal or greater than the mean is labeled *useful*.\n",
    "\n",
    "The following cell randomly samples for a predefined number of *useful* and *not useful* reviews which are then concatenated together and the resulting df is then shuffled."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "useful_reviews shape:  (500, 3)\n",
      "not_useful_reviews shape:  (500, 3)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>useful</th>\n",
       "      <th>cool</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>218396</th>\n",
       "      <td>The hamburger was fresh and so were the toppin...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5218305</th>\n",
       "      <td>If you're looking for help in the Home departm...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>905548</th>\n",
       "      <td>Heard about this place from friends how great ...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4914250</th>\n",
       "      <td>Sushi in big wooden boats!\\n\\nI have to say, I...</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4019227</th>\n",
       "      <td>We had a great server named Herschel who defin...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                      text  useful  cool\n",
       "218396   The hamburger was fresh and so were the toppin...       0     0\n",
       "5218305  If you're looking for help in the Home departm...       0     0\n",
       "905548   Heard about this place from friends how great ...       0     0\n",
       "4914250  Sushi in big wooden boats!\\n\\nI have to say, I...       4     1\n",
       "4019227  We had a great server named Herschel who defin...       0     1"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "THRESHOLD = round(reviews['useful'].mean()) \n",
    "\n",
    "useful_reviews = reviews.loc[reviews['useful'] >= THRESHOLD].sample(SAMPLE_SIZE)\n",
    "not_useful_reviews = reviews.loc[reviews['useful'] < THRESHOLD].sample(SAMPLE_SIZE)\n",
    "print(\"useful_reviews shape: \", useful_reviews.shape)\n",
    "print(\"not_useful_reviews shape: \", not_useful_reviews.shape)\n",
    "\n",
    "reviews = shuffle(pd.concat([useful_reviews, not_useful_reviews]))\n",
    "reviews.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocessing\n",
    "\n",
    "For `text` a custom `analyzer` method is written which:\n",
    "1. remove all punctuations and\n",
    "3. removes new line characters (escape sequence)\n",
    "\n",
    "The feature extraction (`CountVectorize` and `TfidfVectorizer`) class is then set to:\n",
    "2. remove accents\n",
    "2. remove all stopwords\n",
    "3. lowercase all words\n",
    "\n",
    "For `useful` votes:\n",
    "2. remove df row if `useful` is `NaN`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "reviews shape after dropping NaN values:  (1000, 3)\n"
     ]
    }
   ],
   "source": [
    "reviews.dropna(inplace=True)\n",
    "print(\"reviews shape after dropping NaN values: \", reviews.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import string\n",
    "import re\n",
    "\n",
    "RE_NEWLINE = '\\n+'\n",
    "PUNCTUATIONS = string.punctuation\n",
    "\n",
    "def review_process(review):\n",
    "    no_newline = re.sub(RE_NEWLINE, '', review)\n",
    "    no_punc = ''.join([char for char in no_newline if char not in PUNCTUATIONS])\n",
    "    \n",
    "    return no_punc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a str with some 2 punctuations 6546721 and numbers   \n"
     ]
    }
   ],
   "source": [
    "test = \"a str.. with! some @2 punctuations 6546721 and numbers \\n [] \\n\"\n",
    "print(review_process(test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
       "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
       "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
       "        ngram_range=(1, 1), norm='l2',\n",
       "        preprocessor=<function review_process at 0x14b1c5bf8>,\n",
       "        smooth_idf=True, stop_words='english', strip_accents='ascii',\n",
       "        sublinear_tf=False, token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b',\n",
       "        tokenizer=None, use_idf=True, vocabulary=None)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vect = TfidfVectorizer(strip_accents='ascii', preprocessor=review_process, stop_words='english' )\n",
    "vect"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generating labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "\n",
    "NOT_USEFUL = 0\n",
    "USEFUL = 1\n",
    "\n",
    "def labeler(vote):\n",
    "    if math.floor(vote) < THRESHOLD:\n",
    "        return NOT_USEFUL\n",
    "    else:\n",
    "        return USEFUL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>useful</th>\n",
       "      <th>cool</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>218396</th>\n",
       "      <td>The hamburger was fresh and so were the toppin...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5218305</th>\n",
       "      <td>If you're looking for help in the Home departm...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>905548</th>\n",
       "      <td>Heard about this place from friends how great ...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4914250</th>\n",
       "      <td>Sushi in big wooden boats!\\n\\nI have to say, I...</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4019227</th>\n",
       "      <td>We had a great server named Herschel who defin...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                      text  useful  cool  \\\n",
       "218396   The hamburger was fresh and so were the toppin...       0     0   \n",
       "5218305  If you're looking for help in the Home departm...       0     0   \n",
       "905548   Heard about this place from friends how great ...       0     0   \n",
       "4914250  Sushi in big wooden boats!\\n\\nI have to say, I...       4     1   \n",
       "4019227  We had a great server named Herschel who defin...       0     1   \n",
       "\n",
       "         label  \n",
       "218396       0  \n",
       "5218305      0  \n",
       "905548       0  \n",
       "4914250      1  \n",
       "4019227      0  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reviews['label'] = reviews['useful'].apply(labeler)\n",
    "    \n",
    "reviews.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generating test train splits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, Y_train, Y_test = train_test_split(reviews[['text', 'useful', 'cool']], reviews['label'], test_size=0.4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Instantiate classifiers\n",
    "\n",
    "We will be using 3 classifiers for this analysis namely, *Multinomial Naive Bayes*, *Linear SVM* and *Random Forest*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MultinomialNB(alpha=1.0, class_prior=None, fit_prior=True)\n",
      "\n",
      "\n",
      "LinearSVC(C=1.0, class_weight=None, dual=True, fit_intercept=True,\n",
      "     intercept_scaling=1, loss='squared_hinge', max_iter=1000,\n",
      "     multi_class='ovr', penalty='l2', random_state=None, tol=0.0001,\n",
      "     verbose=0)\n",
      "\n",
      "\n",
      "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
      "            max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
      "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "            min_samples_leaf=1, min_samples_split=2,\n",
      "            min_weight_fraction_leaf=0.0, n_estimators=10, n_jobs=1,\n",
      "            oob_score=False, random_state=None, verbose=0,\n",
      "            warm_start=False)\n"
     ]
    }
   ],
   "source": [
    "mn_clas = MultinomialNB()\n",
    "print(mn_clas)\n",
    "print(\"\\n\")\n",
    "\n",
    "svc_clas = LinearSVC()\n",
    "print(svc_clas)\n",
    "print(\"\\n\")\n",
    "\n",
    "rf_clas = RandomForestClassifier()\n",
    "print(rf_clas)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature selection\n",
    "\n",
    "As we increase the number of data points, the vocabulary of our classifiers will increase which means the number of features extracted will also increase. For a large numebr of data points, this will be memory intensive and will also result in longer training time.\n",
    "\n",
    "To improve the performance of our program, we will remove all zero-variance features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "VarianceThreshold(threshold=0.0)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sel = VarianceThreshold()\n",
    "sel"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model 1: training with only text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape of X1 after feature extraction:  (600, 8663)\n",
      "shape of X1_test after feature extraction:  (600, 8663)\n"
     ]
    }
   ],
   "source": [
    "# feature extraction\n",
    "X1 = vect.fit_transform(X_train['text'])\n",
    "X1_test = vect.transform(X_test['text'])\n",
    "print(\"shape of X1 after feature extraction: \", X1.shape)\n",
    "\n",
    "# feature selection\n",
    "X1 = sel.fit_transform(X1)\n",
    "X1_test = sel.transform(X1_test)\n",
    "print(\"shape of X1_test after feature extraction: \", X1.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "scipy.sparse.csr.csr_matrix"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(X1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "            max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
       "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "            min_samples_leaf=1, min_samples_split=2,\n",
       "            min_weight_fraction_leaf=0.0, n_estimators=10, n_jobs=1,\n",
       "            oob_score=False, random_state=None, verbose=0,\n",
       "            warm_start=False)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mn_clas.fit(X1, Y_train)\n",
    "svc_clas.fit(X1, Y_train)\n",
    "rf_clas.fit(X1, Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Naive Bayes score:  0.5675\n",
      "Linear SVC score:  0.555\n",
      "Random Forest score:  0.5575\n"
     ]
    }
   ],
   "source": [
    "print(\"Naive Bayes score: \", mn_clas.score(X1_test, Y_test))\n",
    "print(\"Linear SVC score: \", svc_clas.score(X1_test, Y_test))\n",
    "print(\"Random Forest score: \", rf_clas.score(X1_test, Y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model 2: training with text and useful votes\n",
    "\n",
    "Since X now contains mixed dtypes, we need to be a bit clever. First, we convert `useful` column for train and test into sparse matrix and *I2* normalize them (I2 is the default for `TfidfVectorizer` so that's what we use here as well).\n",
    "\n",
    "The rest is straight forward, we create our updated X by stacking the `useful` sparse matrices with X horizontally (such that the number of feature increases). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "type of useful_sparse_train:  <class 'scipy.sparse.csr.csr_matrix'>\n",
      "shape of useful_sparse_train:  (1, 600)\n"
     ]
    }
   ],
   "source": [
    "useful_sparse_train = normalize(csr_matrix(X_train['useful']))\n",
    "useful_sparse_test = normalize(csr_matrix(X_test['useful']))\n",
    "print(\"type of useful_sparse_train: \", type(useful_sparse_train))\n",
    "print(\"shape of useful_sparse_train: \", useful_sparse_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape of X2:  (600, 8666)\n"
     ]
    }
   ],
   "source": [
    "# training\n",
    "X2 = hstack([X1, useful_sparse_train.T])\n",
    "print(\"shape of X2: \", X2.shape)\n",
    "\n",
    "# testing\n",
    "X2_test = hstack([X1_test, useful_sparse_test.T])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "            max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
       "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "            min_samples_leaf=1, min_samples_split=2,\n",
       "            min_weight_fraction_leaf=0.0, n_estimators=10, n_jobs=1,\n",
       "            oob_score=False, random_state=None, verbose=0,\n",
       "            warm_start=False)"
      ]
     },
     "execution_count": 148,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mn_clas.fit(X2, Y_train)\n",
    "svc_clas.fit(X2, Y_train)\n",
    "rf_clas.fit(X2, Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Naive Bayes score:  0.5675\n",
      "Linear SVC score:  0.66\n",
      "Random Forest score:  0.9625\n"
     ]
    }
   ],
   "source": [
    "print(\"Naive Bayes score: \", mn_clas.score(X2_test, Y_test))\n",
    "print(\"Linear SVC score: \", svc_clas.score(X2_test, Y_test))\n",
    "print(\"Random Forest score: \", rf_clas.score(X2_test, Y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model 3: training with text and cool votes\n",
    "\n",
    "Next we will carry out the analysis with text and `cool` votes. We choose `cool` votes since it had the second highest correlation with `useful` (see exploration.ipynb)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [],
   "source": [
    "cool_sparse_train = normalize(csr_matrix(X_train['cool']))\n",
    "cool_sparse_test = normalize(csr_matrix(X_test['cool']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape of X3:  (600, 8666)\n"
     ]
    }
   ],
   "source": [
    "# training\n",
    "X3 = hstack([X1, cool_sparse_train.T])\n",
    "print(\"shape of X3: \", X3.shape)\n",
    "\n",
    "# testing\n",
    "X3_test = hstack([X1_test, cool_sparse_test.T])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "            max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
       "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "            min_samples_leaf=1, min_samples_split=2,\n",
       "            min_weight_fraction_leaf=0.0, n_estimators=10, n_jobs=1,\n",
       "            oob_score=False, random_state=None, verbose=0,\n",
       "            warm_start=False)"
      ]
     },
     "execution_count": 154,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mn_clas.fit(X3, Y_train)\n",
    "svc_clas.fit(X3, Y_train)\n",
    "rf_clas.fit(X3, Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Naive Bayes score:  0.4875\n",
      "Linear SVC score:  0.5175\n",
      "Random Forest score:  0.6725\n"
     ]
    }
   ],
   "source": [
    "print(\"Naive Bayes score: \", mn_clas.score(X3_test, Y_test))\n",
    "print(\"Linear SVC score: \", svc_clas.score(X3_test, Y_test))\n",
    "print(\"Random Forest score: \", rf_clas.score(X3_test, Y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model 4: training with text, useful and cool votes\n",
    "\n",
    "Finally we will carry out the analysis with text, `useful` & `cool` votes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape of uc_sparse_train:  (600, 2)\n"
     ]
    }
   ],
   "source": [
    "uc_sparse_train = normalize(csr_matrix(X_train[['cool', 'useful']]))\n",
    "uc_sparse_test = normalize(csr_matrix(X_test[['cool', 'useful']]))\n",
    "print(\"shape of uc_sparse_train: \", uc_sparse_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape of X4:  (600, 8667)\n"
     ]
    }
   ],
   "source": [
    "# training\n",
    "X4 = hstack([X1, uc_sparse_train])\n",
    "print(\"shape of X4: \", X4.shape)\n",
    "\n",
    "# testing\n",
    "X4_test = hstack([X1_test, uc_sparse_test])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "            max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
       "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "            min_samples_leaf=1, min_samples_split=2,\n",
       "            min_weight_fraction_leaf=0.0, n_estimators=10, n_jobs=1,\n",
       "            oob_score=False, random_state=None, verbose=0,\n",
       "            warm_start=False)"
      ]
     },
     "execution_count": 161,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mn_clas.fit(X4, Y_train)\n",
    "svc_clas.fit(X4, Y_train)\n",
    "rf_clas.fit(X4, Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Naive Bayes score:  0.92\n",
      "Linear SVC score:  0.9975\n",
      "Random Forest score:  0.865\n"
     ]
    }
   ],
   "source": [
    "print(\"Naive Bayes score: \", mn_clas.score(X4_test, Y_test))\n",
    "print(\"Linear SVC score: \", svc_clas.score(X4_test, Y_test))\n",
    "print(\"Random Forest score: \", rf_clas.score(X4_test, Y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
